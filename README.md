# ðŸ“° News API ETL Project (Docker + Airflow)

This is a beginner-friendly **Data Engineering Project** that builds a complete ETL pipeline using **News API**, **Apache Airflow**, and **PostgreSQL**, all inside **Docker**.  
The pipeline extracts latest news articles, transforms and cleans the data, loads it into a PostgreSQL database, and visualizes it using Jupyter Notebook.

---

## ðŸš€ Tech Stack Used

- ðŸ Python  
- ðŸ› ï¸ Apache Airflow  
- ðŸ˜ PostgreSQL  
- ðŸ³ Docker & Docker Compose  
- ðŸ“Š Jupyter Notebook  
- ðŸŒ News API  
- ðŸ“¦ Pandas, Requests, SQLAlchemy

---

## ðŸ“ Folder Structure

news_api_etl_project/
â”‚
â”œâ”€â”€ dags/ # Airflow DAGs
â”‚ â””â”€â”€ news_api_etl.py
â”‚
â”œâ”€â”€ scripts/ # ETL Python scripts
â”‚ â””â”€â”€ news_api_extract.py
â”‚
â”œâ”€â”€ data/ # Raw and cleaned data files
â”‚ â”œâ”€â”€ raw_news_data.csv
â”‚ â””â”€â”€ cleaned_news_data.csv
â”‚
â”œâ”€â”€ notebooks/ # Jupyter notebooks for visualization
â”‚ â””â”€â”€ news-api-graphs.ipynb
â”‚
â”œâ”€â”€ images/ # Graphs or DAG screenshots
â”‚ â””â”€â”€ airflow_dag_graph.png
â”‚
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ docker-compose.yml # Docker services
â””â”€â”€ dockerfile # Dockerfile for Airflow image


---


---

## ðŸš€ How to Run the Project (Using Docker)

> ðŸ“¦ **Prerequisites:**
> - Docker & Docker Compose installed

### ðŸ”¹ Step 1: Clone the Repository
```bash
git clone https://github.com/varshasahay/news_api_etl_project.git
cd news_api_etl_project
docker-compose up --build

